{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d2decf8-2817-46c7-9e4f-65fa3ed1ec38",
   "metadata": {},
   "source": [
    "# Kobling og dublettkontroll\n",
    "Dette er fra grunnkurset med noen nye tillegg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a47af1-60ba-48a8-86c6-8b33580ed33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e5ad45-1e8e-4898-880e-259ae3d3a407",
   "metadata": {},
   "source": [
    "## Koble filer\n",
    "Vi bruker merge når vi skal koble filer. Denne fungerer som en sql join. Det betyr at alle kobler med alle med samme nøkkel. Vi kan velge om vi skal ta med de som ikke kobler.\n",
    "\n",
    "Vi starter med å lese inn 2 filer som, når de kobles, inneholder alle varianter av koblinger. Det er disse variantene:\n",
    "- 1:1\n",
    "- 1:mange\n",
    "- mange:1\n",
    "- mange:mange\n",
    "- 1:ingen\n",
    "- mange:ingen\n",
    "- ingen:1\n",
    "- ingen:mange\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b6cf8-8290-4c68-87c6-d0b5b3364ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1file=\"\"\"\n",
    "3 c 03\n",
    "1 a\n",
    "2 b 02\n",
    "4 e 05\n",
    "3 d 04\n",
    "4 f 06\n",
    "4 g 07\n",
    "7 i 09\n",
    "5 h 08\n",
    "7 j 10\n",
    "\"\"\"\n",
    "reg1 = pd.read_csv(\n",
    "        StringIO(reg1file),\n",
    "        names=['id', 'mstat', 'county'],\n",
    "        dtype=object,\n",
    "        header=None,\n",
    "        sep=' '\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d9dca1-bc35-4af1-b5ba-9e15df6eb6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reg2file=\"\"\"\n",
    "2 y 19\n",
    "1 z 20\n",
    "2 x 18\n",
    "4 v 06\n",
    "3 w 17\n",
    "4 u 15\n",
    "8 s 12\n",
    "6 t 14\n",
    "8 r 11\n",
    "\"\"\"\n",
    "reg2 = pd.read_csv(\n",
    "        StringIO(reg2file),\n",
    "        names=['id', 'cstat', 'county'],\n",
    "        dtype=object,\n",
    "        header=None,\n",
    "        sep=' '\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8fa8de-2e9c-45a2-9fa9-dc62a55e11e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(reg1, reg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6539b4b1-c548-4e36-8b54-74d4134f531a",
   "metadata": {},
   "source": [
    "## Standard merge (inner join)\n",
    "Vi starter med en standard merge. Den tilsvarer en inner join i sql. Vi ser at variabler med samme navn i de dataframes som kobles kommer med med hvert sitt nye variabelnavn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee987de1-9c84-47fd-8fdb-116cf30a9a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(reg1, reg2, on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c4a58-a74a-4e2d-9e2b-0bd81175542c",
   "metadata": {},
   "source": [
    "Resultatet ble ikke sortert på nøkkelen id. Vi kan legge til det med sort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df12068a-04c5-4276-b15b-40a13b5111f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(reg1, reg2, on='id').sort_values('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6803341a-28a2-4049-afb1-a09480c619f9",
   "metadata": {},
   "source": [
    "Nøklene kan ha forskjellige navn. Da angir vi navnet på nøkkelvariablene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9056b8ef-35fa-4f33-b266-db723ec4f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(reg1, \n",
    "         reg2, \n",
    "         left_on='id', \n",
    "         right_on='id'\n",
    "        ).sort_values('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71944259-97d5-49f1-af99-adc1f93f7950",
   "metadata": {},
   "source": [
    "## Full join\n",
    "Vi kan gjøre en full join. Da vil alle som ikke kobler også komme med i resultatet. Vi angir koblingstypen med how-parameteren. Det er også lurt å ta med en indikator slik at vi kan se hvor de enkelte radene kommer fra. Variabler som har samme navn i begge filene uten å være en del av nøklene får nye navn: suffiks _x og _y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfed7c8-7dba-4e55-8aaf-86cd68f93ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(reg1, \n",
    "         reg2, \n",
    "         on='id', \n",
    "         how='outer', \n",
    "         indicator=True\n",
    "        ).sort_values('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754ce68b-6079-4396-8d67-12ed8be6cad1",
   "metadata": {},
   "source": [
    "Vi kan velge suffiks selv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63de887-7e59-4fef-9e66-254b5abc1444",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(reg1, \n",
    "         reg2, \n",
    "         on='id', \n",
    "         how='outer', \n",
    "         indicator=True, \n",
    "         suffixes = ('_1', '_2')\n",
    "        ).sort_values('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76c4725-f751-4231-be19-67b891d775b7",
   "metadata": {},
   "source": [
    "## Left join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10bfeeb-bf16-4445-891f-74d7b368f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(reg1, \n",
    "         reg2, \n",
    "         on='id',\n",
    "         how='left', \n",
    "         indicator=True\n",
    "        ).sort_values('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c31a8e-d0a7-41b7-a954-1fa174cfef0d",
   "metadata": {},
   "source": [
    "## Right join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d280a4-cdba-4615-9141-76ba93d762e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(reg1, \n",
    "         reg2, \n",
    "         on='id', \n",
    "         how='right', \n",
    "         indicator=True\n",
    "        ).sort_values('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431b4e0a-f69a-40b1-a366-ec26009a890e",
   "metadata": {},
   "source": [
    "## Lagre resultatet\n",
    "Vi kan lagre koblingen i en panda dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8cbbc-7543-43f7-86f2-73439f2c9016",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.merge(reg1, \n",
    "                reg2, \n",
    "                on='id', \n",
    "                how='left', \n",
    "                indicator=True\n",
    "               ).sort_values('id')\\\n",
    "                .copy()\n",
    "left"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95773f6-7fc6-4e39-8990-78aef6b5cd79",
   "metadata": {},
   "source": [
    "## Sjekke forekomster\n",
    "Hvis vi bare vil se hvilke identer som er i reg2 uten å hente noe data derfra kan vi bruke et oppslag med isin og bare returnere de som er der (= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0752671-2bb7-4f78-a446-5d2d60d36b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1[reg1['id'].isin(reg2['id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac32b26-7fff-4f8f-ac34-4aeb79311144",
   "metadata": {},
   "source": [
    "Vi kan gjøre det motsatte med masken ved å bruke \"~\" og finne de som er i reg1, men ikke i reg2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd5c526-7bcf-43ae-b487-a1b18fc140aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1[~reg1['id'].isin(reg2['id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170ac60f-80cc-42b8-83c6-eab7efd89b75",
   "metadata": {},
   "source": [
    "## Sette sammen dataene under hverandre (append = concat)\n",
    "Vi kan også sette sammen dataene våre etter hverandre istedenfor å koble dem. Vi kan bruke concat til det. Vi ser at variabler som ikke er i begge datasett får NaN-verdi fra det datasettet de ikke er i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb69078-ac2a-447e-93aa-4f388e38eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([reg1, reg2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c34deff-dddb-49d4-bb27-e58bc2ceece2",
   "metadata": {},
   "source": [
    "## Dublettsjekk\n",
    "Vi starter med å liste alle like rader. Først lager vi et datasett som har like rader, deretter bruker vi duplicated til å fjerne dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60e5bde-43a7-4345-aa2f-df97ae3f0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1_4 = reg1[reg1['id'] == '4'].copy()\n",
    "reg1_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88b0f61-6410-445c-9783-eda3987857bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1dubl = pd.concat([reg1, reg1_4])\n",
    "reg1dubl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc58c0b-8b9b-472e-adc3-40f5122b8635",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1dubl[~reg1dubl.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fece7c3-01dd-4973-aaa8-b06e1e3d0b98",
   "metadata": {},
   "source": [
    "Nå skal vi liste dubletter på id-variabelen i det opprinnelige reg1-datasettet. Vi sorterer resultatet slik at det blir lettere å tolke resultatet.\n",
    "Her blir alle som ikke er første dublett listet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a9861b-6b0c-4672-9f12-d79304922be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1[reg1.duplicated(['id'], keep='first')].sort_values(['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ab6422-f521-467f-81de-5e880abe7114",
   "metadata": {},
   "source": [
    "Her blir alle unntatt den siste listet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f365a5b-babf-4d3b-b9fb-83416834d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1[reg1.duplicated(['id'], keep='last')].sort_values(['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4bd1b4-d8c4-4bfe-acdd-5bc792f48646",
   "metadata": {},
   "source": [
    "Nå lister vi alle dubletter på id-variabelen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49386e89-e3cf-46c8-84ba-909501a81d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1[reg1.duplicated(['id'], keep=False)].sort_values(['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367a03c2-48ad-4ced-ac33-56a4ddaf1ab7",
   "metadata": {},
   "source": [
    "Vi kan velge å beholde kun den første dubletten for hver id på datasettet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8918257a-bdb5-4c65-9c57-c2ab46e1a159",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1[~reg1.duplicated(['id'], keep='first')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f864fe-7796-46f5-9ca6-8e567342db80",
   "metadata": {},
   "source": [
    "Vi kan velge å beholde kun den siste dubletten for hver id på datasettet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75bf529-9967-40aa-8860-5aedae85eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1[~reg1.duplicated(['id'], keep='last')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (gammel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

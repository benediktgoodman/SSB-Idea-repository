{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dapla as dp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_iterations = 4\n",
    "start_year = 2019\n",
    "population_size = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = {}\n",
    "pops = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_path = '/felles/mock_sysselsatte/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(extra_iterations+1):\n",
    "    print(start_year + i)\n",
    "    comps[start_year + i] = f'{start_path}companies_{start_year + i}_{population_size}'\n",
    "    pops[start_year + i] = f'{start_path}population_{start_year + i}_{population_size}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in pops.items():\n",
    "    pops[key] = dp.read_pandas(item)\n",
    "for key, item in comps.items():\n",
    "    comps[key] = dp.read_pandas(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "works = {}\n",
    "for key, item in pops.items():\n",
    "    print(key)\n",
    "    works[key] = item.merge(comps[key], how= 'left', on = 'work_id')\\\n",
    "            .drop('employee_points', axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = works[start_year].columns.tolist().append('date')\n",
    "work_long = pd.DataFrame(columns = cols)\n",
    "\n",
    "for key, item in works.items():\n",
    "    work_tmp = item\n",
    "    work_tmp['date'] = f'{key}-09-01'\n",
    "    work_long = pd.concat([work_long, work_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_long_outpath = f'{start_path}/work_long_{start_year}-{start_year + extra_iterations}_{population_size}'\n",
    "dp.write_pandas(work_long, work_long_outpath, valuation='OPEN', state= 'OUTPUT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_long.to_csv(f'work_long_{start_year}-{start_year + extra_iterations}_{population_size}_v001.csv', sep = ';', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-depth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
